"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[9981],{3905:(t,e,r)=>{r.d(e,{Zo:()=>m,kt:()=>k});var n=r(67294);function a(t,e,r){return e in t?Object.defineProperty(t,e,{value:r,enumerable:!0,configurable:!0,writable:!0}):t[e]=r,t}function l(t,e){var r=Object.keys(t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),r.push.apply(r,n)}return r}function o(t){for(var e=1;e<arguments.length;e++){var r=null!=arguments[e]?arguments[e]:{};e%2?l(Object(r),!0).forEach((function(e){a(t,e,r[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(r)):l(Object(r)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(r,e))}))}return t}function i(t,e){if(null==t)return{};var r,n,a=function(t,e){if(null==t)return{};var r,n,a={},l=Object.keys(t);for(n=0;n<l.length;n++)r=l[n],e.indexOf(r)>=0||(a[r]=t[r]);return a}(t,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(t);for(n=0;n<l.length;n++)r=l[n],e.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(t,r)&&(a[r]=t[r])}return a}var p=n.createContext({}),s=function(t){var e=n.useContext(p),r=e;return t&&(r="function"==typeof t?t(e):o(o({},e),t)),r},m=function(t){var e=s(t.components);return n.createElement(p.Provider,{value:e},t.children)},u="mdxType",d={inlineCode:"code",wrapper:function(t){var e=t.children;return n.createElement(n.Fragment,{},e)}},g=n.forwardRef((function(t,e){var r=t.components,a=t.mdxType,l=t.originalType,p=t.parentName,m=i(t,["components","mdxType","originalType","parentName"]),u=s(r),g=a,k=u["".concat(p,".").concat(g)]||u[g]||d[g]||l;return r?n.createElement(k,o(o({ref:e},m),{},{components:r})):n.createElement(k,o({ref:e},m))}));function k(t,e){var r=arguments,a=e&&e.mdxType;if("string"==typeof t||a){var l=r.length,o=new Array(l);o[0]=g;var i={};for(var p in e)hasOwnProperty.call(e,p)&&(i[p]=e[p]);i.originalType=t,i[u]="string"==typeof t?t:a,o[1]=i;for(var s=2;s<l;s++)o[s]=r[s];return n.createElement.apply(null,o)}return n.createElement.apply(null,r)}g.displayName="MDXCreateElement"},49054:(t,e,r)=>{r.r(e),r.d(e,{assets:()=>m,contentTitle:()=>p,default:()=>k,frontMatter:()=>i,metadata:()=>s,toc:()=>u});var n=r(87462),a=r(63366),l=(r(67294),r(3905)),o=["components"],i={title:"Bringing LLM Power to Every Pipeline \u2013 The Multi-Model Prompt Processor",author:"Grainier Perera",authorURL:"https://github.com/grainier",authorImageURL:"/img/about/grainier.png"},p="The Multi-Model Prompt Processor",s={permalink:"/blog/2025/04/28/prompt-processor",source:"@site/blog/2025-04-28-prompt-processor.md",title:"Bringing LLM Power to Every Pipeline \u2013 The Multi-Model Prompt Processor",description:"Need a quick sentiment check, a rolling summary, or a safety rule that\u2019s just a bit too fuzzy for SQL?",date:"2025-04-28T00:00:00.000Z",formattedDate:"April 28, 2025",tags:[],readingTime:3.78,hasTruncateMarker:!1,authors:[{name:"Grainier Perera",url:"https://github.com/grainier",imageURL:"/img/about/grainier.png"}],frontMatter:{title:"Bringing LLM Power to Every Pipeline \u2013 The Multi-Model Prompt Processor",author:"Grainier Perera",authorURL:"https://github.com/grainier",authorImageURL:"/img/about/grainier.png"},nextItem:{title:"How to Use the JavaScript Evaluator Processor",permalink:"/blog/2025/04/09/javascript-processor"}},m={authorsImageUrls:[void 0]},u=[{value:"What does the processor do?",id:"what-does-the-processor-do",level:2},{value:"Five ways to use it",id:"five-ways-to-use-it",level:2},{value:"Tutorial \u2013 from stream to JSON warning",id:"tutorial--from-stream-to-json-warning",level:2},{value:"Prompt writing tips for event streams",id:"prompt-writing-tips-for-event-streams",level:2},{value:"Supported models",id:"supported-models",level:2},{value:"Final thoughts",id:"final-thoughts",level:2}],d={toc:u},g="wrapper";function k(t){var e=t.components,r=(0,a.Z)(t,o);return(0,l.kt)(g,(0,n.Z)({},d,r,{components:e,mdxType:"MDXLayout"}),(0,l.kt)("img",{src:"/img/blog/2025-04-28/prompt-processor-pipeline.png",alt:"Prompt Processor in Pipeline"}),(0,l.kt)("p",null,"Need a quick sentiment check, a rolling summary, or a safety rule that\u2019s just a bit too fuzzy for SQL?",(0,l.kt)("br",{parentName:"p"}),"\n","With the ",(0,l.kt)("strong",{parentName:"p"},"Multi-Model Prompt Processor")," you can drop the full might of OpenAI, Anthropic, or your own Llama into any\nApache StreamPipes pipeline\u2014no extra code required."),(0,l.kt)("p",null,"Below you\u2019ll find:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"A quick tour of the options"),(0,l.kt)("li",{parentName:"ul"},"Five every day use-cases"),(0,l.kt)("li",{parentName:"ul"},"A hands-on GIF tutorial"),(0,l.kt)("li",{parentName:"ul"},"Tips on writing prompts that return ",(0,l.kt)("strong",{parentName:"li"},"only")," what you need"),(0,l.kt)("li",{parentName:"ul"},"A full list of the models that work out of the box")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"what-does-the-processor-do"},"What does the processor do?"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Option"),(0,l.kt)("th",{parentName:"tr",align:null},"What it controls"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Model provider / name")),(0,l.kt)("td",{parentName:"tr",align:null},"Choose any OpenAI or Anthropic model, or point to a Llama on Ollama.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Temperature")),(0,l.kt)("td",{parentName:"tr",align:null},"0 = repeatable answers, 1 = creative answers.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"History strategy")),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("em",{parentName:"td"},"Stateless"),", ",(0,l.kt)("em",{parentName:"td"},"Windowed (N turns)"),", or ",(0,l.kt)("em",{parentName:"td"},"Full")," history.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Window size")),(0,l.kt)("td",{parentName:"tr",align:null},"How many past turns to keep in ",(0,l.kt)("em",{parentName:"td"},"Windowed")," mode.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Multiple input fields")),(0,l.kt)("td",{parentName:"tr",align:null},"Combine several event attributes into one user message.")))),(0,l.kt)("p",null,"The processor sends your prompt + current event data to the model, grabs the reply, and writes it to a new field\n",(0,l.kt)("inlineCode",{parentName:"p"},"llmResponse"),"; ideal when the answer must flow straight into the next processor."),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"five-ways-to-use-it"},"Five ways to use it"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"#"),(0,l.kt)("th",{parentName:"tr",align:null},"Scenario"),(0,l.kt)("th",{parentName:"tr",align:null},"Prompt idea (few-shot style)"),(0,l.kt)("th",{parentName:"tr",align:null},"History"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"1"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Data-quality gate")," \u2013 flag numbers > 15"),(0,l.kt)("td",{parentName:"tr",align:null},"Return WARNING if value > 15 else OK. Example \u2192 12 \u2192 OK, 18 \u2192 WARNING."),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Stateless"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"2"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Rolling minimum")," of a sensor"),(0,l.kt)("td",{parentName:"tr",align:null},"Pass previousMin + current. \u201cReturn the smallest of the two numbers only.\u201d"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Windowed (1)"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"3"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Five-tweet sentiment")),(0,l.kt)("td",{parentName:"tr",align:null},"Concatenate last 5 tweets. \u201cReturn POSITIVE / NEGATIVE / NEUTRAL only.\u201d"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Windowed (5)"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"4"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Chat summariser")," for support tickets"),(0,l.kt)("td",{parentName:"tr",align:null},"System prompt: \u201cWrite one-line summary of the whole conversation.\u201d"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Full"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"5"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Dynamic threshold helper")),(0,l.kt)("td",{parentName:"tr",align:null},"Feed last 10 load values. \u201cReturn max(values)*1.1 rounded 0 decimals.\u201d"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("strong",{parentName:"td"},"Windowed (10)"))))),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"(Replace the ",(0,l.kt)("inlineCode",{parentName:"em"},"$placeholders$")," with the actual stream attributes in the mapping dialog.)")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"tutorial--from-stream-to-json-warning"},"Tutorial \u2013 from stream to JSON warning"),(0,l.kt)("p",null,"Below is a short clip showing the processor in action in a temperature pipeline.",(0,l.kt)("br",{parentName:"p"}),"\n","The prompt forces the model to output a two-field JSON\u2014perfect for machine parsing."),(0,l.kt)("img",{src:"/img/blog/2025-04-28/prompt_processor_demo.gif",alt:"Animated demo of the prompt processor"}),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Model:")," ",(0,l.kt)("inlineCode",{parentName:"p"},"claude-3-5-sonnet-20241022"),(0,l.kt)("br",{parentName:"p"}),"\n",(0,l.kt)("strong",{parentName:"p"},"Prompt Used:")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},'You are an assistant that ALWAYS replies with a single JSON object\ncontaining two string fields: "status" and "message".\n\nRules\n1. If the temperature is strictly greater than 45 \xb0C:\n     \u2022 "status" must be "WARNING"\n     \u2022 "message" must explain that the temperature is above the safe limit\n2. Otherwise:\n     \u2022 "status" must be "OK"\n     \u2022 "message" must note that the temperature is within the safe range\n3. Do not output anything except the JSON object.\n\n### Examples\n\nTemperature: 50\n{\n  "status": "WARNING",\n  "message": "Temperature exceeds the 45 \xb0C threshold"\n}\n\nTemperature: 30\n{\n  "status": "OK",\n  "message": "Temperature is within the safe range"\n}\n\nTemperature: 45\n{\n  "status": "OK",\n  "message": "Temperature is within the safe range"\n}\n\nTemperature: 60\n{\n  "status": "WARNING",\n  "message": "Temperature exceeds the 45 \xb0C threshold"\n}\n')),(0,l.kt)("p",null,"The model now returns either:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "status": "WARNING",\n  "message": "Temperature exceeds the 45 \xb0C threshold"\n}\n')),(0,l.kt)("p",null,"or"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "status": "OK",\n  "message": "Temperature is within the safe range"\n}\n')),(0,l.kt)("p",null,"Nothing else\u2014exactly what we want for downstream processors."),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"prompt-writing-tips-for-event-streams"},"Prompt writing tips for event streams"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"State the output format first"),": \u201cReply with OK or WARNING only.\u201d"),(0,l.kt)("li",{parentName:"ol"},"Give ",(0,l.kt)("strong",{parentName:"li"},"one or two concrete examples")," \u2013 LLMs copy patterns."),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"End with a clear cue"),": \u201cAnswer:\u201d or \u201cOutput:\u201d."),(0,l.kt)("li",{parentName:"ol"},"Keep ",(0,l.kt)("em",{parentName:"li"},"temperature \u2264 0.3")," when strict structure matters."),(0,l.kt)("li",{parentName:"ol"},"Short replies reduce context size in ",(0,l.kt)("em",{parentName:"li"},"Windowed")," / ",(0,l.kt)("em",{parentName:"li"},"Full")," modes.")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"supported-models"},"Supported models"),(0,l.kt)("details",null,(0,l.kt)("summary",null,(0,l.kt)("strong",null,"Anthropic models")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"claude-3-7-sonnet-20250219\nclaude-3-5-sonnet-20241022\nclaude-3-5-haiku-20241022\nclaude-3-5-sonnet-20240620\nclaude-3-opus-20240229\nclaude-3-sonnet-20240229\nclaude-3-haiku-20240307\nclaude-2.1\nclaude-2.0\n"))),(0,l.kt)("details",null,(0,l.kt)("summary",null,(0,l.kt)("strong",null,"OpenAI models")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"gpt-3.5-turbo              gpt-3.5-turbo-1106     gpt-3.5-turbo-0125\ngpt-3.5-turbo-16k          gpt-4                  gpt-4-0613\ngpt-4-turbo-preview        gpt-4-1106-preview     gpt-4-0125-preview\ngpt-4-turbo                gpt-4-turbo-2024-04-09 gpt-4-32k\ngpt-4-32k-0613             gpt-4o                 gpt-4o-2024-05-13\ngpt-4o-2024-08-06          gpt-4o-2024-11-20      gpt-4o-mini\ngpt-4o-mini-2024-07-18     o1                     o1-mini\no1-2024-12-17              o1-mini-2024-09-12     o1-preview\no1-preview-2024-09-12      o3-mini-2025-01-31\n"))),(0,l.kt)("details",null,(0,l.kt)("summary",null,(0,l.kt)("strong",null,"Llama suggestions (Ollama)")),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"llama3"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"llama3:8b"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"llama2"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"mistral-7b-instruct"),", or any custom model you have pulled.")),(0,l.kt)("hr",null),(0,l.kt)("h2",{id:"final-thoughts"},"Final thoughts"),(0,l.kt)("p",null,"Whether you need a lightweight rule engine, live summaries, or just a smarter filter, the Multi-Model Prompt Processor\ndrops straight into your pipeline and starts working within minutes."),(0,l.kt)("p",null,"Give it a try, and let us know what you build!"))}k.isMDXComponent=!0}}]);