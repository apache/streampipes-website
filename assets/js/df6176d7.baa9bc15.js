"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[84435],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>h});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},m=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=p(n),d=i,h=c["".concat(l,".").concat(d)]||c[d]||u[d]||o;return n?a.createElement(h,r(r({ref:t},m),{},{components:n})):a.createElement(h,r({ref:t},m))}));function h(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,r=new Array(o);r[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:i,r[1]=s;for(var p=2;p<o;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},17040:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>p,toc:()=>c});var a=n(87462),i=n(63366),o=(n(67294),n(3905)),r=["components"],s={title:"Anomaly Detection with StreamPipes Functions in Python and ONNX",author:"Tim Bossenmaier",authorURL:"https://github.com/bossenti",authorImageURL:"/img/bossenmaier.png"},l=void 0,p={permalink:"/blog/2024/03/27/anomaly-detection-with-python-functions",source:"@site/blog/2024-03-27-anomaly-detection-with-python-functions.md",title:"Anomaly Detection with StreamPipes Functions in Python and ONNX",description:"Apache StreamPipes saves the day when it comes to connecting to data sources in the IIoT world. Want to do more with",date:"2024-03-27T00:00:00.000Z",formattedDate:"March 27, 2024",tags:[],readingTime:5.38,hasTruncateMarker:!0,authors:[{name:"Tim Bossenmaier",url:"https://github.com/bossenti",imageURL:"/img/bossenmaier.png"}],frontMatter:{title:"Anomaly Detection with StreamPipes Functions in Python and ONNX",author:"Tim Bossenmaier",authorURL:"https://github.com/bossenti",authorImageURL:"/img/bossenmaier.png"},prevItem:{title:"Apache StreamPipes release 0.95.0",permalink:"/blog/2024/06/13/release-095"},nextItem:{title:"Apache StreamPipes release 0.93.0",permalink:"/blog/2023/11/28/release-093"}},m={authorsImageUrls:[void 0]},c=[{value:"Motivation",id:"motivation",level:2},{value:"Set Up &amp; Prepare Python Client",id:"set-up--prepare-python-client",level:2},{value:"Model Training with Historic Data",id:"model-training-with-historic-data",level:2},{value:"Model Inference with Live Data",id:"model-inference-with-live-data",level:2}],u={toc:c},d="wrapper";function h(e){var t=e.components,n=(0,i.Z)(e,r);return(0,o.kt)(d,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Apache StreamPipes saves the day when it comes to connecting to data sources in the IIoT world. Want to do more with\nyour IIoT data than just analyze it in a dashboard? If so, this blog post is for you! We'll show you how to extract\nhistorical data from StreamPipes, use it to train a machine learning model, bring the model back to StreamPipes using\nONNX, and apply the model to live data."),(0,o.kt)("center",null,(0,o.kt)("img",{class:"blog-image",style:{maxWidth:"75%"},src:"/img/blog/2024-03-26/prediction-analysis.png",alt:"anomaly-detection"}),(0,o.kt)("br",null)),(0,o.kt)("h2",{id:"motivation"},"Motivation"),(0,o.kt)("p",null,"With this blogpost we want to illustrate how one can easily extract historical IIoT data collected with StreamPipes,\ntrain a machine learning model on this data and bringing the model back to StreamPipes with the interoperability\nstandard ",(0,o.kt)("a",{parentName:"p",href:"https://onnx.ai"},"ONNX")," to make inference in live data."),(0,o.kt)("p",null,"A very common use case in the area of IIoT is the detection of anomalies, so we want to tackle this challenge in this\narticle as well. We will use data generated by\nthe ",(0,o.kt)("a",{parentName:"p",href:"https://streampipes.apache.org/docs/pe/org.apache.streampipes.connect.iiot.adapters.simulator.machine/"},"Machine Data Simulator"),"\nadapter. More specifically, we will focus on the ",(0,o.kt)("inlineCode",{parentName:"p"},"flowrate")," data, which consists of various sensor values coming from a\nwater pipe system. Our goal is to keep an eye on the parameter ",(0,o.kt)("inlineCode",{parentName:"p"},"volume_flow"),", which represents the current volume flow\nin\ncubic meters/second. For this parameter, we want to detect anomalies that could indicate problems such as leaks,\nblockages, etc."),(0,o.kt)("p",null,"To get the concerned data, we simply need to create an instance of the machine data simulator and persist the data in\nthe data lake:"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://raw.githubusercontent.com/apache/streampipes/dev/streampipes-client-python/docs/img/tutorial-preparation.gif",alt:"tutorial-preparation"})),(0,o.kt)("h2",{id:"set-up--prepare-python-client"},"Set Up & Prepare Python Client"),(0,o.kt)("p",null,"As a prerequisite, we need to install the StreamPipes Python client and all other dependencies,"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"pip install git+https://github.com/apache/streampipes.git#subdirectory=streampipes-client-python\npip install scikit-learn==1.4.0 skl2onnx==1.16.0 onnxruntime==1.17.1\n")),(0,o.kt)("p",null,"The next step is to configure and initialize an instance of the client."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import os\nfrom streampipes.client import StreamPipesClient\nfrom streampipes.client.config import StreamPipesClientConfig\nfrom streampipes.client.credential_provider import StreamPipesApiKeyCredentials\n\nos.environ["BROKER-HOST"] = "localhost"\nos.environ["KAFKA-PORT"] = "9094"  # When using Kafka as message broker\n\nconfig = StreamPipesClientConfig(\n    credential_provider=StreamPipesApiKeyCredentials(\n        username="admin@streampipes.apache.org",\n        api_key="TOKEN",\n    ),\n    host_address="localhost",\n    https_disabled=True,\n    port=80\n)\n\nclient = StreamPipesClient(client_config=config)\n')),(0,o.kt)("p",null,"In case you have never worked with the Python client before and have problems to get started,\nplease have a look at\nour ",(0,o.kt)("a",{parentName:"p",href:"https://streampipes.apache.org/docs/docs/python/latest/tutorials/1-introduction-to-streampipes-python-client/"},"tutorial"),"."),(0,o.kt)("p",null,"If you already have an ONNX model and are only interested in applying it with StreamPipes on a data stream, you can skip\nthe following section."),(0,o.kt)("h2",{id:"model-training-with-historic-data"},"Model Training with Historic Data"),(0,o.kt)("p",null,"As said above, the aim of our model is to detect anomalies of the ",(0,o.kt)("inlineCode",{parentName:"p"},"volume_flow")," parameter. For this task, we will use\n",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Isolation_forest"},"Isolation Forests"),". Please note that the focus of the tutorial is not\non training the model, so please be patient even though the training is very simplified and lacks important preparation\nsteps such as standardization."),(0,o.kt)("p",null,"As a first step, lets query the ",(0,o.kt)("inlineCode",{parentName:"p"},"flowrate")," data from the StreamPipes data lake and extract the values of ",(0,o.kt)("inlineCode",{parentName:"p"},"volume_flow"),"\nas a feature:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'flowrate_df = client.dataLakeMeasureApi.get("flow-rate").to_pandas()\nX = flowrate_df["volume_flow"].values.reshape(-1, 1).astype("float32")\n')),(0,o.kt)("p",null,"As a next step, we can already train our model with the historic data:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from sklearn.ensemble import IsolationForest\n\nmodel = IsolationForest(contamination=0.01)\nmodel.fit(X)\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"contamination")," parameter models the proportion of outliers in the data. See\nthe ",(0,o.kt)("a",{parentName:"p",href:"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html"},"scikit-learn"),"\ndocumentation for more information."),(0,o.kt)("p",null,"Here you can see how this simple model performs:"),(0,o.kt)("img",{src:"/img/blog/2024-03-26/prediction-analysis.png"}),(0,o.kt)("p",null),(0,o.kt)("p",null,"This doesn't look too bad, right? Let's continue by converting our model to the ONNX representation."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from onnxconverter_common import FloatTensorType\nfrom skl2onnx import to_onnx\n\nmodel_onnx = to_onnx(\n    model,\n    initial_types=[('input', FloatTensorType([None, X.shape[1]]))],\n    target_opset={'ai.onnx.ml': 3, 'ai.onnx': 15, '': 15}\n)\n\nwith open(\"isolation_forest.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())\n")),(0,o.kt)("h2",{id:"model-inference-with-live-data"},"Model Inference with Live Data"),(0,o.kt)("p",null,"Utilizing a pre-trained model within StreamPipes becomes seamless with the ONNX interoperability standard, enabling\neffortless application of your existing model on live data streams."),(0,o.kt)("p",null,"Interacting with live data from StreamPipes is facilitated through StreamPipes functions. Below, we'll create a Python\nStreamPipes function that leverages an ONNX model to generate predictions for each incoming event, making the results\naccessible as a data stream within StreamPipes for subsequent steps."),(0,o.kt)("p",null,"So let's create an ",(0,o.kt)("inlineCode",{parentName:"p"},"ONNXFunction")," that is capable of applying a model in ONNX representation to a StreamPipes data\nstream.\nIf you'd like to read more details about how functions are defined, refer\nto ",(0,o.kt)("a",{parentName:"p",href:"https://streampipes.apache.org/docs/docs/python/latest/tutorials/3-getting-live-data-from-the-streampipes-data-stream/"},"our tutorial"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import numpy as np\nimport onnxruntime as rt\n\nfrom streampipes.functions.broker.broker_handler import get_broker_description\nfrom streampipes.functions.streampipes_function import StreamPipesFunction\nfrom streampipes.functions.utils.data_stream_generator import create_data_stream, RuntimeType\nfrom streampipes.functions.utils.function_context import FunctionContext\nfrom streampipes.model.resource import FunctionDefinition, DataStream\n\nfrom typing import Dict, Any, List\n\n\nclass ONNXFunction(StreamPipesFunction):\n\n    def __init__(self, feature_names: list[str], input_stream: DataStream):\n        output_stream = create_data_stream(\n            name="flowrate-prediction",\n            attributes={\n                "is_anomaly": RuntimeType.BOOLEAN.value\n            },\n            broker=get_broker_description(input_stream)\n        )\n\n        function_definition = FunctionDefinition(\n            consumed_streams=[input_stream.element_id]\n        ).add_output_data_stream(output_stream)\n\n        self.feature_names = feature_names\n        self.input_name = None\n        self.output_name = None\n        self.session = None\n\n        super().__init__(function_definition=function_definition)\n    \n    ...\n')),(0,o.kt)("p",null,"First, we need to take care about the data stream that is required to send the predictions from our function to\nStreamPipes. Thus, we create a dedicated output data stream which we need to provide with the attributes our event will\nconsist of (a timestamp attribute is always added automatically). This output data stream needs to be registered at the\nfunction definition which is to be passed to the parent class. Lastly, we need to define some instance variables that\nare mainly required for the ONNX runtime."),(0,o.kt)("p",null,"Next, we need to ensure that ONNX runtime session is created on start up. Thus, we need to invoke an InferenceSession\nand retrieving the corresponding configuration parameters:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'class ONNXFunction(StreamPipesFunction):\n  \n    ...\n    \n    def onServiceStarted(self, context: FunctionContext) -> None:\n        self.session = rt.InferenceSession(\n            path_or_bytes="isolation_forest.onnx",\n            providers=rt.get_available_providers(),\n        )\n        self.input_name = self.session.get_inputs()[0].name\n        self.output_name = self.session.get_outputs()[0].name\n        \n    ...\n\n')),(0,o.kt)("p",null,"Lastly, we need to implement the inference logic that is applied to every event.\nIf you have brought up your own model, you need to adapt line ",(0,o.kt)("inlineCode",{parentName:"p"},"10-13"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python",metastring:"jsx {10-13} showLineNumbers",jsx:!0,"{10-13}":!0,showLineNumbers:!0},'class ONNXFunction(StreamPipesFunction):\n\n    ...\n\n    def onEvent(self, event: Dict[str, Any], streamId: str) -> None:\n        feature_vector = []\n        for feature in self.feature_names:\n            feature_vector.append(event[feature])\n\n        prediction = self.session.run(\n            [self.output_name],\n            {self.input_name: np.expand_dims(np.array(feature_vector), axis=0).astype("float32")}\n        )[0]\n\n        output = {\n            "is_anomaly": int(prediction[0]) == -1\n        }\n\n        self.add_output(\n            stream_id=self.function_definition.get_output_stream_ids()[0],\n            event=output\n        )\n\n    def onServiceStopped(self) -> None:\n        pass\n')),(0,o.kt)("p",null,"Having the function code in place, we can start the function with the following:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from streampipes.functions.registration import Registration\nfrom streampipes.functions.function_handler import FunctionHandler\n\nstream = [\n    stream\n    for stream\n    in client.dataStreamApi.all()\n    if stream.name == "flow-rate"\n][0]\n\nfunction = ONNXFunction(\n    feature_names=["volume_flow"],\n    input_stream=stream\n)\n\nregistration = Registration()\nregistration.register(function)\nfunction_handler = FunctionHandler(registration, client)\nfunction_handler.initializeFunctions()\n')),(0,o.kt)("p",null,"We can now access the live values of the prediction in the StreamPipes UI, e.g., in the pipeline editor."),(0,o.kt)("img",{src:"/img/blog/2024-03-26/tutorial-prediction-data-stream.png"}),(0,o.kt)("p",null),(0,o.kt)("p",null,"From here on you can further work with the prediction events in StreamPipes, e.g., by sending notifications\nto ",(0,o.kt)("a",{parentName:"p",href:"https://streampipes.apache.org/docs/next/pe/org.apache.streampipes.sinks.notifications.jvm.msteams/"},"MS Teams"),"."))}h.isMDXComponent=!0}}]);