"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[38319],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>u});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},h="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),h=c(a),m=r,u=h["".concat(l,".").concat(m)]||h[m]||p[m]||s;return a?n.createElement(u,o(o({ref:t},d),{},{components:a})):n.createElement(u,o({ref:t},d))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[h]="string"==typeof e?e:r,o[1]=i;for(var c=2;c<s;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},59746:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>c,toc:()=>h});var n=a(87462),r=a(63366),s=(a(67294),a(3905)),o=["components"],i={title:"How to understand your machine data?",author:"Philipp Zehnder",authorURL:"http://twitter.com/philipp10der",authorImageURL:"/img/zehnder.png"},l=void 0,c={permalink:"/blog/2018/06/18/how-to-understand-your-machine-data",source:"@site/blog/2018-06-18-how-to-understand-your-machine-data.md",title:"How to understand your machine data?",description:"8 minutes to read",date:"2018-06-18T00:00:00.000Z",formattedDate:"June 18, 2018",tags:[],readingTime:6.7,hasTruncateMarker:!0,authors:[{name:"Philipp Zehnder",url:"http://twitter.com/philipp10der",imageURL:"/img/zehnder.png"}],frontMatter:{title:"How to understand your machine data?",author:"Philipp Zehnder",authorURL:"http://twitter.com/philipp10der",authorImageURL:"/img/zehnder.png"},prevItem:{title:"Preview: StreamPipes release 0.60.0",permalink:"/blog/2018/09/17/preview-060"},nextItem:{title:"Welcome to StreamPipes!",permalink:"/blog/2018/06/14/welcome"}},d={authorsImageUrls:[void 0]},h=[],p={toc:h},m="wrapper";function u(e){var t=e.components,a=(0,r.Z)(e,o);return(0,s.kt)(m,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},(0,s.kt)("div",{style:{float:"left",paddingRight:"40px"}},"8 minutes to read"))),(0,s.kt)("br",null),(0,s.kt)("p",null,"Data is the new oil. Probably everybody of you has heard or read this sentence before.\nIt is often stated how important data and data understanding is for companies today.\nBut what does this actually mean?  How does the data look like that is produced by your machines and systems?\nAnd how can we solve the big challenge to turn this raw data into insights that can be understood by humans?"),(0,s.kt)("p",null,"When it comes to data analytics people often talk about the big players like Google, Facebook, or Netflix which collect a lot of data about their users and their usage behavior.\nThe core of their business model is to use data and turn it into profit. Nowadays all companies have the requirement to analyze their data.\nBut since this was not originally part of their business model it is very challenging for them to catch up.\nTo gain insights from data, it is often referred to advanced analytics and machine learning. Before such techniques can be used some work must be done.\nA first, basic part of that is to understand your data. We do that in four steps, as can be seen in figure below.\nFirst data sources must be accessed, then they can be integrated and for example be stored in a data lake.\nAfter that, we employ rule-based analytics to find patterns and situations.\nIn the end, machine learning and advanced analytics algorithms can be used to get more out of the data.\nThe idea behind those steps is to generate value as early as possible by collecting the low-hanging fruits first.\nWe develop methodologies and tools for the individual steps to also allow domain experts to perform them to bridge the gap between the big tech companies and more traditional industries."),(0,s.kt)("img",{className:"blog-image",style:{maxWidth:"50%"},src:"/img/blog/2018-06-18/01_motivation.png",alt:"Motivation Graphic"}),(0,s.kt)("p",null,"The questions we try to answer in these blog posts are:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"How does data produced by machines look like?")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"How can machines and other data sources be accessed?")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"How is it possible to process the continuously produced flow of data?"))),(0,s.kt)("p",null,"We illustrate our ideas with an example which we also use during the whole blog series.\nThe example is a water circle of a cooling system. You can see such a system in the next image.\nIt contains multiple water tanks and pipes that connect those tanks.\nWithin the tanks and the pipes are multiple sensors, which measure for example the water level in the tank, the flow rate in the water pipe, or the temperature of the water.\nAll those sensors are very simple, they make iterative observations and send the sensed measurements to a computer system."),(0,s.kt)("img",{class:"blog-image",style:{maxWidth:"70%"},src:"/img/blog/2018-06-18/02_anlage.png",alt:"Water Circle Image"}),(0,s.kt)("p",null,"Before we go into detail, we want to explain the term streaming data, because we focus on machine and sensor data which is continually produced in a streaming fashion.\nThe opposite of streaming data are fixed sized data sets, called batch data.\nSince always new data is produced by sensors, it is not possible to wait till all data is completely produced and then process it.\nDifferent to that is batch data.\nThe advantage of batch data is, when the processing starts no new data is added anymore.\nStreaming data can also be processed with batch processing systems.\nTherefore, a data stream must be separated into fixed chunks which are then processed in a batch fashion.\nThis is possible but the more natural fit is to use streaming systems since they were designed to process streaming data."),(0,s.kt)("p",null,"In an environment where we process machine data we have different components.\nThe individual components exchange information in the form of ",(0,s.kt)("strong",{parentName:"p"},"events"),".\nAll assets continually producing data are called ",(0,s.kt)("strong",{parentName:"p"},"data sources")," (i.e. a sensor, machine or a software system).\nTo access these data sources, ",(0,s.kt)("strong",{parentName:"p"},"adapters")," are needed.\nAdapters are software components (which can run anywhere, for example directly on the machine or separately on a edge device near the machine) that are able to connect to the data source, extract the sensor information and emit events to the ",(0,s.kt)("strong",{parentName:"p"},"middleware"),".\nThe middleware is a central component which is an intermediate between the individual components.\nEven if the middleware is a central component, it is not a bottleneck and also not a single point of failure since it is often realized in form of a distributed system.\n",(0,s.kt)("strong",{parentName:"p"},"Processing systems")," can access data from the middleware, transform it and apply algorithms.\nThis is the component where the data is analyzed and higher-level information is generated.\nIn the end, results can be stored in ",(0,s.kt)("strong",{parentName:"p"},"data bases"),".\nFrom there, other applications like for example dashboards can access the calculated results.\nThis is the high-level architecture of processing data streams."),(0,s.kt)("img",{class:"blog-image",src:"/img/blog/2018-06-18/03_architecture.png",alt:"Overall architecture"}),(0,s.kt)("p",null,"Once the events are integrated into a middleware, it must be processed to detect situations and generate higher-level events.\nThis can be done in an ",(0,s.kt)("strong",{parentName:"p"},"Event Processing Network (EPN)"),".\nAn EPN consists of one or multiple ",(0,s.kt)("strong",{parentName:"p"},"data sources, event processors")," transforming and detecting patterns in the data and finally ",(0,s.kt)("strong",{parentName:"p"},"data sinks"),", which can be data bases, alarms or other systems.\nBelow such a pipeline is shown where we have two sensors as data sources: A flow rate sensor measuring the flow rate in a water pipe and a water level sensor in a water tank.\nIt further contains three processing elements, each with a different functionality.\nThe first one detects increases in the water tank, the second one filters out values under a defined threshold.\nThe last of the processing elements detects when both situations occur within a defined time window.\nIn the end, we employ a data sink, which triggers a notification for a service technician once the modeled situation occurs.\nWe call such instances of EPNs processing ",(0,s.kt)("strong",{parentName:"p"},"pipelines"),"."),(0,s.kt)("img",{class:"blog-image",src:"/img/blog/2018-06-18/04_pipeline.png",alt:"Example Pipeline"}),(0,s.kt)("p",null,"The pipeline in the image before contains three different processing elements.\nThose elements contain the actual algorithms.\nSuch algorithms can be as easy as simple filters on a sensor value or can also be more complex, such as patterns that occur over a period of time.\nBut they can also contain machine learning and advanced analytics algorithms (e.g. neural networks) that perform predictions on data streams.\nEvent processors are just an abstraction that take a data stream as an input and expose a \u201cnew\u201d data stream.\nFurthermore, they contain configuration parameters which can be defined by a user.\nWith this concept, we can create reusable components that can be used in many different pipelines."),(0,s.kt)("p",null,"The goal of StreamPipes is to enable domain experts to do their data analysis themselves by providing tooling, where such processing pipelines can be modeled in a graphical user interface and then executed automatically without the need of an IT expert.\nProcessing engines which are used as the basis of the processing elements in our solution often require a higher technological understanding.\nIf this understanding is available, they can also be used on their own.\nWe use such systems, like Apache Flink, Apache Spark or the brand-new KSQL by Confluent, for the processing but provide an abstraction over them to enable domain experts to model pipelines themselves.\nThis has also the advantages that individual runtime solutions can be exchanged over time.\nFurthermore, we provide a semantic layer for all elements, including data sources, processing elements, and data sinks.\nWith that layer, our system is capable of understanding the meaning and further support the user to ensure that just semantically correct pipelines are created."),(0,s.kt)("p",null,"In this first blog post of our series, we gave a first introduction how data produced by machines and systems can be analyzed and value can be generated out of it.\nIn the following blog posts we explain the individual parts in more detail to provide you with enough knowledge to start analyzing your own data."),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("a",{parentName:"strong",href:"/docs/blog/2018/06/18/how-to-understand-your-machine-data"},"Part 1: Overview"))),(0,s.kt)("li",{parentName:"ul"},"Part 2: Data Sources"),(0,s.kt)("li",{parentName:"ul"},"Part 3: Data Processing Elements"),(0,s.kt)("li",{parentName:"ul"},"Part 4: Data Sinks"),(0,s.kt)("li",{parentName:"ul"},"Part 5: Putting it all together (Example Pipeline)"),(0,s.kt)("li",{parentName:"ul"},"Part 6: Practical Tips")))}u.isMDXComponent=!0}}]);