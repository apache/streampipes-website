"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[91107],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>h});var r=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var c=r.createContext({}),p=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},l=function(e){var t=p(e.components);return r.createElement(c.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,a=e.originalType,c=e.parentName,l=o(e,["components","mdxType","originalType","parentName"]),u=p(n),m=i,h=u["".concat(c,".").concat(m)]||u[m]||d[m]||a;return n?r.createElement(h,s(s({ref:t},l),{},{components:n})):r.createElement(h,s({ref:t},l))}));function h(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var a=n.length,s=new Array(a);s[0]=m;var o={};for(var c in t)hasOwnProperty.call(t,c)&&(o[c]=t[c]);o.originalType=e,o[u]="string"==typeof e?e:i,s[1]=o;for(var p=2;p<a;p++)s[p]=n[p];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},45809:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>p,toc:()=>u});var r=n(87462),i=n(63366),a=(n(67294),n(3905)),s=["components"],o={id:"technicals-architecture",title:"Architecture",sidebar_label:"Architecture",original_id:"technicals-architecture"},c=void 0,p={unversionedId:"technicals-architecture",id:"version-0.90.0/technicals-architecture",title:"Architecture",description:"The following picture illustrates the high-level architecture of StreamPipes:",source:"@site/versioned_docs/version-0.90.0/07_technicals-architecture.md",sourceDirName:".",slug:"/technicals-architecture",permalink:"/docs/0.90.0/technicals-architecture",draft:!1,tags:[],version:"0.90.0",lastUpdatedBy:"Dominik Riemer",lastUpdatedAt:1688364542,formattedLastUpdatedAt:"Jul 3, 2023",sidebarPosition:7,frontMatter:{id:"technicals-architecture",title:"Architecture",sidebar_label:"Architecture",original_id:"technicals-architecture"},sidebar:"documentation",previous:{title:"Migration Guide: 0.69.0",permalink:"/docs/0.90.0/extend-sdk-migration-service-discovery"},next:{title:"User Guidance",permalink:"/docs/0.90.0/technicals-user-guidance"}},l={},u=[{value:"Semantic description",id:"semantic-description",level:2}],d={toc:u},m="wrapper";function h(e){var t=e.components,n=(0,i.Z)(e,s);return(0,a.kt)(m,(0,r.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The following picture illustrates the high-level architecture of StreamPipes:"),(0,a.kt)("img",{src:"/img/architecture/high-level-architecture.png",alt:"High Level Architecture of StreamPipes"}),(0,a.kt)("p",null,"Users mainly interact (besides other UI components) with the ",(0,a.kt)("em",{parentName:"p"},"Pipeline Editor")," to create stream processing pipelines based on data streams, data processors and data sinks.\nThese reusable pipeline elements are provided by self-contained ",(0,a.kt)("em",{parentName:"p"},"pipeline element containers"),", each of them having a semantic description that specifies their characteristics (e.g., input, output and required user input for data processors).\nEach pipeline element container has a REST endpoint that provides these characteristics as a JSON-LD document."),(0,a.kt)("p",null,"Pipeline element containers are built using one of several provided ",(0,a.kt)("em",{parentName:"p"},"wrappers"),".\nWrappers abstract from the underlying runtime stream processing framework.\nCurrently, the StreamPipes framework provides wrappers for Apache Flink, Esper and algorithms running directly on the JVM."),(0,a.kt)("p",null,"The ",(0,a.kt)("em",{parentName:"p"},"pipeline manager")," manages the definition and execution of pipelines.\nWhen creating pipelines, the manager continuously matches the pipeline against its semantic description and provides user guidance in form of recommendations.\nOnce a pipeline is started, the pipeline manager invokes the corresponding pipeline element containers.\nThe container prepares the actual execution logic and submits the program to the underlying execution engine, e.g., the program is deployed in the Apache Flink cluster."),(0,a.kt)("p",null,"Pipeline elements exchange data using one or more message brokers and protocols (e.g., Kafka or MQTT).\nStreamPipes does not rely on a specific broker or message format, but negotiates suitable brokers based on the capabilities of connected pipeline elements."),(0,a.kt)("p",null,"Thus, StreamPipes provides a higher-level abstraction of existing stream processing technology by leveraging domain experts to create streaming analytics pipelines in a self-service manner."),(0,a.kt)("h2",{id:"semantic-description"},"Semantic description"),(0,a.kt)("p",null,"Pipeline elements in StreamPipes are meant to be reusable:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Data processors and data sink are generic (or domain-specific) elements that express their requirements and are able to operate on any stream that satisfies these requirements."),(0,a.kt)("li",{parentName:"ul"},"Data processors and data sinks can be manually configured by offering possible configuration parameters which users can individually define when creating pipelines."),(0,a.kt)("li",{parentName:"ul"},"Data streams can be connected to any data processor or data sink that matches the capabilities of the stream.")),(0,a.kt)("p",null,"When users create pipelines by connecting a data stream with a data processor (or further processors), the pipeline manager ",(0,a.kt)("em",{parentName:"p"},"matches")," the input stream of a data processor against its requirements.\nThis matching is performed based on the _semantic description of each element.\nThe semantic description (technically an RDF graph serialized as JSON-LD) can be best understood by seeing it as an envelope around a pipeline element.\nIt only provides metadata information, while we don't rely on any RDF at runtime for exchanging events between pipeline elements.\nWhile RDF-based metadata ensures good understanding of stream capabilities, lightweight event formats at runtime (such as JSON or Thrift) ensure fast processing of events."),(0,a.kt)("p",null,"Let's look at an example stream that produces a continuous stream of vehicle positions as illustrated below:"),(0,a.kt)("img",{src:"/img/architecture/semantic-description-stream.png",alt:"Semantic description of data streams"}),(0,a.kt)("p",null,"While the runtime layer produces plain JSON by submitting actual values of the position and the vehicle's plate number, the description layer describes various characteristics of the stream:\nFor instance, it defines the event schema (including, besides the data type and the runtime name of each property also a more fine-grained meaning of the property), quality aspects (e.g., the measurement unit of a property or the frequency) and the grounding (e.g., the format used at runtime and the communication protocol used for transmitting events)."),(0,a.kt)("p",null,"The same accounts for data processors and data sinks:"),(0,a.kt)("img",{src:"/img/architecture/semantic-description-processor.png",alt:"Semantic description of data processor"}),(0,a.kt)("p",null,"Data processors (and, with some differences, data sinks) are annotated by providing metadata information on their required input and output.\nFor instance, we can define minimum schema requirements (such as geospatial coordinates that need to be provided by any stream that is connected to a processor), but also required (minimum or maximum) quality levels and supported transport protocols and formats.\nIn addition, required configuration parameters users can define during the pipeline definition process are provided by the semantic description."),(0,a.kt)("p",null,"Once new pipeline elements are imported into StreamPipes, we store all information provided by the description layer in a central repository and use this information to guide useres through the pipeline definition process."),(0,a.kt)("p",null,"Don't worry - you will never be required to model RDF by yourself.\nOur SDK provides convenience methods that help creating the description automatically."))}h.isMDXComponent=!0}}]);