"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[9981],{3905:(e,r,t)=>{t.d(r,{Zo:()=>s,kt:()=>f});var n=t(67294);function o(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function a(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?a(Object(t),!0).forEach((function(r){o(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function p(e,r){if(null==e)return{};var t,n,o=function(e,r){if(null==e)return{};var t,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||(o[t]=e[t]);return o}(e,r);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var c=n.createContext({}),l=function(e){var r=n.useContext(c),t=r;return e&&(t="function"==typeof e?e(r):i(i({},r),e)),t},s=function(e){var r=l(e.components);return n.createElement(c.Provider,{value:r},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},g=n.forwardRef((function(e,r){var t=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),u=l(t),g=o,f=u["".concat(c,".").concat(g)]||u[g]||m[g]||a;return t?n.createElement(f,i(i({ref:r},s),{},{components:t})):n.createElement(f,i({ref:r},s))}));function f(e,r){var t=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var a=t.length,i=new Array(a);i[0]=g;var p={};for(var c in r)hasOwnProperty.call(r,c)&&(p[c]=r[c]);p.originalType=e,p[u]="string"==typeof e?e:o,i[1]=p;for(var l=2;l<a;l++)i[l]=t[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}g.displayName="MDXCreateElement"},49054:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>s,contentTitle:()=>c,default:()=>f,frontMatter:()=>p,metadata:()=>l,toc:()=>u});var n=t(87462),o=t(63366),a=(t(67294),t(3905)),i=["components"],p={title:"Bringing LLM Power to Every Pipeline \u2013 The Multi-Model Prompt Processor",author:"Grainier Perera",authorURL:"https://github.com/grainier",authorImageURL:"/img/about/grainier.png"},c="The Multi-Model Prompt Processor",l={permalink:"/blog/2025/04/28/prompt-processor",source:"@site/blog/2025-04-28-prompt-processor.md",title:"Bringing LLM Power to Every Pipeline \u2013 The Multi-Model Prompt Processor",description:"Need a quick sentiment check, a rolling summary, or a safety rule that\u2019s just a bit too fuzzy for SQL?",date:"2025-04-28T00:00:00.000Z",formattedDate:"April 28, 2025",tags:[],readingTime:3.785,hasTruncateMarker:!0,authors:[{name:"Grainier Perera",url:"https://github.com/grainier",imageURL:"/img/about/grainier.png"}],frontMatter:{title:"Bringing LLM Power to Every Pipeline \u2013 The Multi-Model Prompt Processor",author:"Grainier Perera",authorURL:"https://github.com/grainier",authorImageURL:"/img/about/grainier.png"},prevItem:{title:"Usage-Based Maintenance with Apache StreamPipes",permalink:"/blog/2025/04/30/usage-based-maintanence"},nextItem:{title:"How to Use the JavaScript Evaluator Processor",permalink:"/blog/2025/04/09/javascript-processor"}},s={authorsImageUrls:[void 0]},u=[],m={toc:u},g="wrapper";function f(e){var r=e.components,t=(0,o.Z)(e,i);return(0,a.kt)(g,(0,n.Z)({},m,t,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("img",{src:"/img/blog/2025-04-28/prompt-processor-pipeline.png",alt:"Prompt Processor in Pipeline"}),(0,a.kt)("p",null,"Need a quick sentiment check, a rolling summary, or a safety rule that\u2019s just a bit too fuzzy for SQL?",(0,a.kt)("br",{parentName:"p"}),"\n","With the ",(0,a.kt)("strong",{parentName:"p"},"Multi-Model Prompt Processor")," you can drop the full might of OpenAI, Anthropic, or your own Llama into any\nApache StreamPipes pipeline\u2014no extra code required."))}f.isMDXComponent=!0}}]);